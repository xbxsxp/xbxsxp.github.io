(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{348:function(s,t,a){s.exports=a.p+"assets/img/Segformer.6e2b569c.jpg"},349:function(s,t,a){s.exports=a.p+"assets/img/POE.3ddee9fe.jpg"},412:function(s,t,a){"use strict";a.r(t);var n=a(4),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"_1-分析setr遗留的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-分析setr遗留的问题"}},[s._v("#")]),s._v(" 1 分析SETR遗留的问题")]),s._v(" "),t("p",[s._v("SETR第一个用Vision Transformer做encoder来尝试做语义分割，并且取得了很好的结果， 具体体现为ADE20K上首次刷到50+ mIoU。这其实迈出了比较重要的一步，说明了Transformer在语义分割上潜力很大，使用Transformer的性能上限可以很高。\n另一方面，SETR也存在一些问题需要解决。 其中比较主要的问题是SETR采用ViT-large作为encoder, 它有以下几个缺点：")]),s._v(" "),t("ul",[t("li",[s._v("ViT-large 参数和计算量非常大，有300M+参数，这对于移动端模型是无法承受的；")]),s._v(" "),t("li",[s._v("ViT的结构不太适合做语义分割，因为ViT是柱状结构，全程只能输出固定分辨率的feature map, 比如1/16, 这么低的分辨率对于语义分割不太友好")]),s._v(" "),t("li",[s._v("ViT的柱状结构意味着一旦增大输入图片或者缩小patch大小，计算量都会成平方级提高，对显存的负担非常大，32G的V100也可能hold不住")]),s._v(" "),t("li",[s._v("位置编码. ViT 用的是固定分辨率的positional embedding, 但是语义分割在测试的时候往往图片的分辨率不是固定的，这时要么对positional embedding做双线性插值，这会损害性能, 要么做固定分辨率的滑动窗口测试，这样效率很低而且很不灵活")])]),s._v(" "),t("p",[s._v("改进之处:")]),s._v(" "),t("ul",[t("li",[s._v("(1) 之前ViT和PVT做patch embedding时，每个patch是独立的，我们这里对patch设计成有overlap的，这样可以保证局部连续性。")]),s._v(" "),t("li",[s._v("(2) 彻底去掉了Positional Embedding, 取而代之的是Mix FFN, 即在feed forward network中引入3x3 deepwise conv传递位置信息。")])]),s._v(" "),t("div",{staticClass:"center-container"},[t("p",[t("img",{attrs:{src:a(348),alt:"在这里插入图片描述"}})])]),t("h2",{attrs:{id:"_2-overlap-patch-marging"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-overlap-patch-marging"}},[s._v("#")]),s._v(" 2 Overlap Patch-marging")]),s._v(" "),t("p",[s._v("Segformer在Swin-Transformer的基础上对Patch-marging进行改进，使得不同的Patch有重叠的部分，这样就引入了局部偏置信息")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("class OverlapPatchEmbed"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn.Module"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),s._v('" Image to Patch Embedding\n    '),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),s._v('"\n\n    def __init__'),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("img_size")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("224")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("patch_size")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("stride")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("in_chans")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("embed_dim")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("768")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n        super"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".__init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        img_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" to_2tuple"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        patch_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" to_2tuple"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("patch_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        self.img_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" img_size\n        self.patch_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" patch_size\n        self.H, self.W "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" img_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" // patch_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", img_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" // patch_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        self.num_patches "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.H * self.W\n        self.proj "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn.Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in_chans, embed_dim, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("kernel_size")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("patch_size, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("stride")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("stride,\n                              "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("padding")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("patch_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" // "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(", patch_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" // "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("))")]),s._v("\n        self.norm "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn.LayerNorm"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("embed_dim"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        self.apply"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self._init_weights"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    def forward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self, x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.proj"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        _, _, H, W "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x.shape\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x.flatten"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".transpose"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.norm"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("return")]),s._v(" x, H, W\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br")])]),t("h2",{attrs:{id:"_2-mix-ffn"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-mix-ffn"}},[s._v("#")]),s._v(" 2 Mix-FFN")]),s._v(" "),t("p",[s._v("Mix-FFN, 即在feed forward network中引入 "),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"SVG"}},[t("svg",{staticStyle:{"vertical-align":"-0.05ex"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"3.557ex",height:"1.554ex",viewBox:"0 -665 1572 687"}},[t("g",{attrs:{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"matrix(1 0 0 -1 0 0)"}},[t("g",{attrs:{"data-mml-node":"math"}},[t("g",{attrs:{"data-mml-node":"mn"}},[t("path",{attrs:{"data-c":"33",d:"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"}})]),t("g",{attrs:{"data-mml-node":"mi",transform:"translate(500, 0)"}},[t("path",{attrs:{"data-c":"78",d:"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"}})]),t("g",{attrs:{"data-mml-node":"mn",transform:"translate(1072, 0)"}},[t("path",{attrs:{"data-c":"33",d:"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"}})])])])])]),s._v(" deepwise conv传递位置信息。")],1),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("class Mlp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn.Module"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n    def __init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self, in_features, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("hidden_features")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("out_features")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("act_layer")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("nn.GELU, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("drop")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n        super"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".__init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        out_features "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" out_features or in_features\n        hidden_features "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" hidden_features or in_features\n        self.fc1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn.Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in_features, hidden_features"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self.dwconv "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" DWConv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hidden_features"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self.act "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" act_layer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self.fc2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn.Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hidden_features, out_features"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self.drop "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn.Dropout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("drop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        self.apply"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self._init_weights"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    def _init_weights"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self, m"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" isinstance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m, nn.Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n            trunc_normal_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m.weight, "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("std")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(".02"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" isinstance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m, nn.Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" and m.bias is not None:\n                nn.init.constant_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m.bias, "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("elif")]),s._v(" isinstance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m, nn.LayerNorm"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n            nn.init.constant_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m.bias, "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            nn.init.constant_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m.weight, "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("elif")]),s._v(" isinstance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m, nn.Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n            fan_out "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" m.kernel_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" * m.kernel_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" * m.out_channels\n            fan_out //"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" m.groups\n            m.weight.data.normal_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", math.sqrt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.0")]),s._v(" / fan_out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("))")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" m.bias is not None:\n                m.bias.data.zero_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    def forward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self, x, H, W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.fc1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.dwconv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x, H, W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.act"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.drop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.fc2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self.drop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("return")]),s._v(" x\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br")])]),t("h2",{attrs:{id:"_3-为什么卷积能进行位置编码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-为什么卷积能进行位置编码"}},[s._v("#")]),s._v(" 3 为什么卷积能进行位置编码")]),s._v(" "),t("p",[s._v("卷积神经网络是局部滤波器，它在有限的区域内通过调整卷积核参数来提取特征，这意味着卷积滤波器能输出对应某个特征的响应，但是以往的研究对于CNN是否同时也编码了位置信息没有给出证明。在这篇文章中，作者检验了这个假设，揭示了在CNN中编码的绝对位置信息的惊人程度。一组综合性的实验证明了这一假设的有效性，并揭示了在深层CNNs中，位置信息是从何而来，以及如何表达这些信息。")]),s._v(" "),t("p",[s._v("文章提出了这么一个假设：位置信息在提取的特征图中是隐式编码的，并且在从视觉场景中分类、检测或分割对象时起着重要的作用。深层神经网络的成功是因为它能学习事物的本质和位置。")]),s._v(" "),t("div",{staticClass:"center-container"},[t("p",[t("img",{attrs:{src:a(349),alt:"在这里插入图片描述"}})])]),t("p",[s._v("作者使用VGG和ResNet结构的网络作为前馈网络(参数冻结)来提取特征，从浅层到深层提取5个leve的特征，然后concat送入Position Encoding Module(该模块开放训练，专注于提取位置信息)。Position Encoding Module的主要目标是验证在分类标签上训练时位置信息是否隐式学习")]),s._v(" "),t("p",[s._v("定量实验证明，PosENet（VGG和ResNet）可以很容易地从经过训练的CNN模型中提取位置信息，特别是基于ResNet的PosENet模型。然而，单独训练PosENet（PosENet）直接从图像来预测的得分要低得多。这一结果表明，仅从输入图像中提取位置信息是非常困难的。只有与深度编码网络相耦合，PosENet才能提取出与地面真实位置图一致的位置信息。后续的实验证明了做卷积的zero-padding会在特征途中引入边界和位置信息。")])])}),[],!1,null,null,null);t.default=e.exports}}]);