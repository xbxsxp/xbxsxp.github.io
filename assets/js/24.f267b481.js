(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{350:function(n,e,r){n.exports=r.p+"assets/img/swinunet.a6129f44.jpg"},413:function(n,e,r){"use strict";r.r(e);var t=r(4),a=Object(t.a)({},(function(){var n=this,e=n._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":n.$parent.slotKey}},[e("ul",[e("li",[n._v("医学图像边界模糊、梯度复杂，需要较多的高分辨率信息")]),n._v(" "),e("li",[n._v("人体内部结构相对固定，分割目标在人体图像中的分布很具有规律，语义简单明确，低分辨率的信息就可以简单定位")]),n._v(" "),e("li",[n._v("unet的特点就是通过上采样过程中的级联，使得浅层特征和深层特征结合起来。对于医学图像来说，unet能用深层特征用于定位，浅层特征用于精确分割，这就是为什么unet常见于很多图像分割任务")])]),n._v(" "),e("p",[n._v("在TransUNet中，虽然引入了Transformer用于UNet编码器，但其特点还是CNN与Transformer的混合编码，解码上也是基于CNN的上采样。直观上看，这种混合编码的结构并没有完全发挥出Transformer的优势，并且作为backbone的ViT结构也需要进一步改进。而此前由MSRA提出的Swin Transformer正好作为视觉Transformer领域新的backbone。相较于TransUNet，去掉CNN编码，用 Swin Transformer来代替原先的ViT，将UNet全部结构都换成Swin Transformer。因而，基于Swin Transformer的Swin-UNet就应运而生。")]),n._v(" "),e("h2",{attrs:{id:"swin-unet结构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#swin-unet结构"}},[n._v("#")]),n._v(" swin-unet结构")]),n._v(" "),e("div",{staticClass:"center-container"},[e("p",[e("img",{attrs:{src:r(350),alt:"在这里插入图片描述"}})])]),e("p",[n._v("如图所示，Swin-UNet由Encoder、Bottleneck、Decoder和跳跃连接组成。先看编码器部分，输入图像先进行patch partition，每个patch大小为4x4，输入维度为H/4 x W/4 x 48，经过linear embedding和两个Swin Transformer block后特征图尺寸为H/4 x W/4 x C，然后通过patch merging进行下采样，再经过两个Swin Transformer block后特征图尺寸变为H/8 x W/8 x 2C，最后再进行一次同样的下采样操作即可完成编码器的操作。可以看到，Swin-UNet编码器每次按照2倍来缩小patch的数量，然后按照2倍来扩大特征维度的数量。")]),n._v(" "),e("p",[n._v("Bottleneck则是用了两个连续的Swin Transformer block，这里为防止网络太深不能收敛，所以只用了两个block，在Bottleneck中，特征尺寸保持H/32 x W/32 x 8C不变。")]),n._v(" "),e("p",[n._v("然后是解码器部分。Swin-UNet解码器主要由patch expanding来实现上采样，作为一个完全对称的网络结构，解码器也是每次扩大2倍进行上采样，核心模块由Swin Transformer block和patch expanding组成。")])])}),[],!1,null,null,null);e.default=a.exports}}]);